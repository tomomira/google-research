Google版リサーチツール
要件定義書
バージョン: 1.0
作成日: 2025年11月28日
1. 概要
1.1 プロジェクト背景
クラウドワークスなどのクラウドソーシングサービスでは、Google検索を活用したリサーチ・データ収集案件が多数存在する。これらの案件では、指定されたキーワードで検索を行い、企業情報・店舗情報・ブログ記事などの情報を収集し、Excelにまとめる作業が求められる。
本ツールは、このような作業を効率化・自動化することで、作業時間の短縮と品質の向上を実現することを目的とする。
1.2 目的
1.クラウドワークス等のリサーチ案件に対応できる汎用的なGoogle検索リサーチツールの開発
2.検索キーワードに基づく情報収集の自動化
3.収集データのExcel形式での出力
4.柔軟なカスタマイズによる多様な案件への対応
1.3 対象ユーザー
•クラウドワークスでリサーチ案件を受注するワーカー
•営業リスト作成を行う事業者
•市場調査・競合調査を行うマーケティング担当者
•情報収集業務を効率化したい個人・法人
2. 想定される利用シーン（クラウドワークス案件例）
2.1 企業・店舗リスト作成
案件例：「東京都内の歯科医院をリストアップしてください」
収集項目：医院名、住所、電話番号、URL、診療時間
出力形式：Excelファイル（1行1医院）
2.2 ブログ・記事リサーチ
案件例：「◯◯に関するブログ記事を50件リストアップしてください」
収集項目：記事タイトル、URL、概要、公開日
出力形式：Excelファイル
2.3 競合調査・市場調査
案件例：「特定業界の主要企業情報を収集してください」
収集項目：企業名、URL、事業内容、所在地
出力形式：Excelファイル
3. 機能要件
3.1 検索機能
3.1.1 基本検索機能
1.キーワード入力による検索実行
2.複数キーワードの組み合わせ検索（AND/OR検索）
3.除外キーワードの設定（マイナス検索）
4.フレーズ検索（完全一致検索）
5.検索結果件数の指定（10件〜100件など）
3.1.2 高度な検索オプション
1.地域指定検索（例：「東京都」「大阪府」など）
2.サイト内検索（site:指定）
3.ファイルタイプ指定（filetype:pdf など）
4.期間指定（過去24時間、1週間、1ヶ月、1年など）
5.言語指定（日本語のみなど）
3.2 データ収集機能
3.2.1 標準収集項目
1.ページタイトル
2.URL
3.メタディスクリプション（説明文）
4.検索結果スニペット
5.検索順位
3.2.2 詳細情報収集（オプション：ページ遷移による取得）
1.電話番号の抽出
2.メールアドレスの抽出
3.住所情報の抽出
4.FAX番号の抽出
5.会社名・店舗名の抽出
6.代表者名の抽出
7.営業時間・定休日の抽出
8.SNSリンクの抽出（Twitter/X, Instagram, Facebook等）
3.2.3 カスタム抽出設定
•正規表現による任意パターンの抽出
•CSSセレクタによる特定要素の抽出
•抽出テンプレートの保存・再利用
3.3 出力機能
3.3.1 Excel出力
1.xlsx形式での出力
2.カラム（列）の選択・順序変更
3.ヘッダー行の自動生成
4.列幅の自動調整
5.出力ファイル名のカスタマイズ
3.3.2 その他の出力形式（将来拡張）
•CSV形式
•JSON形式
•Googleスプレッドシート連携
3.4 設定・管理機能
1.検索設定のプリセット保存
2.抽出テンプレートの管理
3.検索履歴の保存・参照
4.処理待機時間の設定（アクセス間隔調整）
5.プロキシ設定（オプション）
4. 非機能要件
4.1 パフォーマンス
•100件の検索結果取得：3分以内（検索結果ページのみ）
•詳細情報取得時：1ページあたり3〜5秒の待機時間を設定
•中断・再開機能による長時間処理への対応
4.2 信頼性
•エラー発生時の適切なエラーハンドリング
•処理途中でのエラー発生時、それまでの結果を保存
•重複データの検出・除外機能
4.3 ユーザビリティ
•直感的なGUI（グラフィカルユーザーインターフェース）
•処理進捗のリアルタイム表示
•日本語UI対応
•マニュアル・ヘルプ機能
4.4 セキュリティ・コンプライアンス
•robots.txtの尊重
•適切なアクセス間隔によるサーバー負荷軽減
•ユーザーエージェントの適切な設定
5. 技術要件
5.1 開発言語・フレームワーク
推奨言語：Python 3.10以上
選定理由：スクレイピングライブラリが充実、Excel操作が容易、学習コストが低い
5.2 主要ライブラリ
ライブラリ	用途	備考
Selenium	ブラウザ自動操作	JavaScript実行が必要な場合に使用
BeautifulSoup4	HTMLパース	検索結果ページの解析
Requests	HTTPリクエスト	基本的なWeb通信
openpyxl	Excel操作	xlsx形式での出力
pandas	データ処理	データの整形・重複除去
tkinter	GUI	デスクトップアプリUI（標準ライブラリ）
CustomTkinter	GUI（モダンUI）	より洗練されたUIを希望する場合
5.3 動作環境
•OS：Windows 10/11、macOS、Linux
•Python：3.10以上
•メモリ：4GB以上推奨
•ネットワーク：インターネット接続必須
6. システム構成
6.1 モジュール構成
google_research/
├── main.py                    # メインエントリーポイント
├── gui/                       # GUI関連モジュール
│   ├── main_window.py       # メインウィンドウ
│   ├── search_panel.py      # 検索設定パネル
│   └── result_panel.py      # 結果表示パネル
├── core/                      # コア機能モジュール
│   ├── searcher.py          # Google検索実行
│   ├── scraper.py           # 詳細情報スクレイピング
│   └── extractor.py         # 情報抽出ロジック
├── output/                    # 出力関連モジュール
│   └── excel_writer.py      # Excel出力
├── config/                    # 設定関連
│   ├── settings.py          # アプリケーション設定
│   └── templates/           # 抽出テンプレート
└── utils/                     # ユーティリティ
6.2 処理フロー
1.ユーザーが検索キーワード・オプションを入力
2.Google検索を実行し、検索結果ページを取得
3.検索結果からタイトル・URL・説明文を抽出
4.（オプション）各URLにアクセスして詳細情報を取得
5.収集データを整形・重複除去
6.Excel形式でファイル出力
7. UI設計（画面構成案）
7.1 メイン画面
•検索キーワード入力エリア：テキストフィールド（複数行対応）
•検索オプション：地域指定、期間指定、件数指定のドロップダウン・チェックボックス
•抽出項目選択：チェックボックスリスト
•実行ボタン：検索開始、中止ボタン
•進捗表示：プログレスバー、処理件数表示
•結果プレビュー：テーブル形式でのリアルタイム表示
7.2 設定画面
•待機時間設定
•出力先フォルダ設定
•プリセット管理
•テンプレート編集
8. 注意事項・制限事項
8.1 Google利用規約について
Googleの検索結果の自動取得（スクレイピング）は、Googleの利用規約に抵触する可能性がある。本ツールの使用は自己責任で行い、過度なアクセスは避けること。商用利用や大量のデータ収集を行う場合は、Google Custom Search JSON APIの利用を推奨する。
8.2 対策・推奨事項
1.適切なアクセス間隔の設定（最低3秒以上推奨）
2.1日あたりの検索回数の制限
3.CAPTCHAが表示された場合の処理中断
4.将来的なGoogle Custom Search API対応の検討
5.robots.txtの確認・遵守
8.3 技術的制限
•JavaScript実行が必要なページの情報取得には限界がある
•ログインが必要なページは取得不可
•Google検索結果のHTML構造変更により、機能が動作しなくなる可能性あり
9. 開発スケジュール（案）
フェーズ	期間	内容
Phase 1	1週間	基本検索機能・Excel出力機能の実装
Phase 2	1週間	詳細情報抽出機能の実装
Phase 3	1週間	GUI実装・ユーザビリティ改善
Phase 4	1週間	テスト・バグ修正・ドキュメント作成
10. 将来の拡張計画
•Google Custom Search API対応
•Googleマップ（ビジネス情報）との連携
•AIによる情報抽出の精度向上（自然言語処理）
•バッチ処理・スケジュール実行機能
•クラウド版（Web版）の開発検討
•Amazon版・楽天版との共通モジュール化
付録：用語集
用語	説明
スクレイピング	Webサイトから情報を自動的に抽出する技術
クローリング	Webサイトを自動的に巡回してデータを収集すること
CAPTCHA	人間とボットを区別するための認証システム
robots.txt	クローラーに対してアクセス可否を指示するファイル
Custom Search API	Googleが提供する公式の検索API
CSSセレクタ	HTML要素を特定するための記法
正規表現	文字列のパターンを表現する記法
